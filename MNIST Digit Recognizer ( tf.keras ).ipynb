{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read train and test csv\n",
    "train = pd.read_csv(\"train.csv\") #label,pixel0,pixel1,...,pixel783\n",
    "test_x = pd.read_csv(\"test.csv\") #pixel0,pixel1,...,pixel783 (No Label)\n",
    "train_y=train['label'] #Our target only the labels \n",
    "train_x=train.drop('label','columns') #Our source only the pixels, we drop the column 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the first 2000 for training, the remain for validation\n",
    "train_x,dev_x=train_x[2000:],train_x[:2000] \n",
    "train_y,dev_y=train_y[2000:],train_y[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 784) (40000,) (2000, 784) (2000,)\n"
     ]
    }
   ],
   "source": [
    "#Data shape\n",
    "print(train_x.shape,train_y.shape,dev_x.shape,dev_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas to numpy\n",
    "train_x=train_x.values\n",
    "train_y=train_y.values\n",
    "dev_x=dev_x.values\n",
    "dev_y=dev_y.values\n",
    "#Transform targets [0,9,...,7] to [[1,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,1],...,[0,0,0,0,0,0,0,1,0,0]]\n",
    "train_y = tf.keras.utils.to_categorical(train_y, 10)\n",
    "dev_y = tf.keras.utils.to_categorical(dev_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 12, 12, 64)        1664      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 1, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 536,718\n",
      "Trainable params: 536,332\n",
      "Non-trainable params: 386\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((28,28,1), input_shape=(784,))) #Reshape input [Pixel0,...,Pixel783] to [Pixel0,.......,Pixel27]\n",
    "                                                                                                        # [......................]\n",
    "                                                                                                        # [......................]\n",
    "                                                                                                        # [Pixel256,...,Pixel783]    \n",
    "model.add(tf.keras.layers.BatchNormalization()) #BachNorm\n",
    "model.add(tf.keras.layers.Activation(\"relu\"))   #Relu Activation\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), strides=(2,2))) #2D Convolution Layer\n",
    "model.add(tf.keras.layers.BatchNormalization()) #BachNorm\n",
    "model.add(tf.keras.layers.Activation(\"relu\")) #Relu Activation\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(5, 5), strides=(2,2))) #2D Convolution Layer\n",
    "model.add(tf.keras.layers.BatchNormalization()) #BachNorm\n",
    "model.add(tf.keras.layers.Activation(\"relu\")) #Relu Activation\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256, (3, 3), strides=(2,2))) #2D Convolution Layer\n",
    "model.add(tf.keras.layers.Dropout(0.5)) #Dropout\n",
    "model.add(tf.keras.layers.Flatten()) #Flatten the 'squared' matrix to a (1,784) vector \n",
    "model.add(tf.keras.layers.Dense(128,activation='relu')) #Dense Layer with relu activation\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax')) #Dense Layer with softmax activation so it can predict one of the 10 Labels\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 0.6239 - acc: 0.8052 - val_loss: 0.8054 - val_acc: 0.9245\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.1692 - acc: 0.9488 - val_loss: 0.7290 - val_acc: 0.8650\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.1248 - acc: 0.9613 - val_loss: 0.5080 - val_acc: 0.8955\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0864 - acc: 0.9735 - val_loss: 0.5865 - val_acc: 0.8035\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0747 - acc: 0.9767 - val_loss: 0.4800 - val_acc: 0.8295\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0523 - acc: 0.9843 - val_loss: 0.1603 - val_acc: 0.9520\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0576 - acc: 0.9809 - val_loss: 0.1863 - val_acc: 0.9420\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0368 - acc: 0.9879 - val_loss: 0.0861 - val_acc: 0.9695\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0312 - acc: 0.9900 - val_loss: 0.1606 - val_acc: 0.9475\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0601 - acc: 0.9821 - val_loss: 0.0495 - val_acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6e2abf29b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(train_x, train_y,\n",
    "          batch_size=1000,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(dev_x, dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the test set\n",
    "prediction=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results\n",
    "final=pd.DataFrame(np.array(prediction.argmax(axis=1)),columns=['Label'])\n",
    "final.index += 1 \n",
    "final.index.names = ['ImageId']\n",
    "final.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
